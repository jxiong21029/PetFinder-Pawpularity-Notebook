{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install + Import Packages\nInternet is disabled, so .whl files are uploaded to a Kaggle dataset","metadata":{}},{"cell_type":"code","source":"!pip install python-box --no-index --find-links=file:///kaggle/input/python-box-dicts","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:51:18.723904Z","iopub.execute_input":"2021-10-16T18:51:18.724261Z","iopub.status.idle":"2021-10-16T18:51:28.311734Z","shell.execute_reply.started":"2021-10-16T18:51:18.724183Z","shell.execute_reply":"2021-10-16T18:51:28.310622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport glob\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.io import read_image\nfrom torchvision import transforms\nfrom sklearn.model_selection import ShuffleSplit\nfrom box import Box\n\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nimport pytorch_lightning as pl\nfrom pytorch_lightning.utilities.seed import seed_everything\nfrom pytorch_lightning.callbacks import EarlyStopping, GPUStatsMonitor\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning import LightningModule, LightningDataModule","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-16T18:51:28.314713Z","iopub.execute_input":"2021-10-16T18:51:28.315051Z","iopub.status.idle":"2021-10-16T18:51:37.316766Z","shell.execute_reply.started":"2021-10-16T18:51:28.315007Z","shell.execute_reply":"2021-10-16T18:51:37.315657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = Box({\n    'seed': 42,\n    'epochs': {\n        'pretrain': 5,\n        'meta_ps': 15,\n        'finetune': 5,\n    },\n    'trainer': {\n        'gpus': 1,\n        'precision': 16,\n        'num_sanity_val_steps': 0,\n        'fast_dev_run': False,\n    },\n    'model_name': 'swin_tiny_patch4_window7_224',\n    'lr': 1e-5,\n    'batch_size': 64,\n    'splits': 3,\n    'val_size': 0.1,\n})\n\nseed_everything(config.seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:51:37.318789Z","iopub.execute_input":"2021-10-16T18:51:37.319114Z","iopub.status.idle":"2021-10-16T18:51:37.341002Z","shell.execute_reply.started":"2021-10-16T18:51:37.319074Z","shell.execute_reply":"2021-10-16T18:51:37.339953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Datasets & Dataloaders (w/ Augmentation)","metadata":{}},{"cell_type":"code","source":"# For this competition in particular, some augmentations may have a significant impact on the\n# \"correct\" labels for each image (e.g. a squashed image may get a lower score) so only a minimal\n# number of transformations are used for now. \nmy_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomHorizontalFlip(),\n        transforms.ConvertImageDtype(torch.float),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ]),\n    'val': transforms.Compose([\n        transforms.ConvertImageDtype(torch.float),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:51:37.344719Z","iopub.execute_input":"2021-10-16T18:51:37.344942Z","iopub.status.idle":"2021-10-16T18:51:37.354632Z","shell.execute_reply.started":"2021-10-16T18:51:37.344918Z","shell.execute_reply":"2021-10-16T18:51:37.353543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PawpularityDataset(Dataset):\n    def __init__(self, df, image_size=224, test=False):\n        self.image_paths = df['Id'].apply(lambda x: os.path.join('../input/petfinder-pawpularity-score', 'test' if test else 'train', x + '.jpg')).values\n        self.labels = None\n        if 'Pawpularity' in df.keys():\n            self.labels = df['Pawpularity'].values\n        self.transform = transforms.Resize([image_size, image_size])\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image = read_image(self.image_paths[idx])\n        image = self.transform(image)\n        if self.labels is not None:\n            label = self.labels[idx]\n            return image, label\n        return image\n\n    \nclass UnlabeledDataset(Dataset):\n    def __init__(self, image_paths, image_size=224):\n        self.image_paths = image_paths\n        self.transform = transforms.Resize([image_size, image_size])\n    \n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, idx):\n        try:\n            image = read_image(self.image_paths[idx])\n        except Exception as e:\n            print(f'Failed to load {self.image_paths[idx]} normally, perhaps image has an alpha channel?')\n            from PIL import Image\n            image = Image.open(self.image_paths[idx])\n            image = torch.tensor(np.moveaxis(np.array(image)[:, :, :3], 2, 0))\n        image = self.transform(image)\n        return image\n\n\n# Datamodule for semi-supervised training\nclass PawpularitySSLDataModule(LightningDataModule):\n    def __init__(self, labeled_data_dir, split: int, unlabeled_globs=None):\n        super().__init__()\n        self.labeled_data_dir = labeled_data_dir\n        self.unlabeled_globs = unlabeled_globs\n        self.split = split\n    \n    def prepare_data(self):\n        if self.unlabeled_globs == None:\n            return\n        datasets = []\n        for globstr in self.unlabeled_globs:\n            image_paths = glob.glob(globstr)\n            if len(image_paths) == 0:\n                raise FileNotFoundError\n            datasets.append(UnlabeledDataset(image_paths))\n        self.unlabeled_dataset = torch.utils.data.ConcatDataset(datasets)\n    \n    def setup(self, stage=None):\n        if stage in (None, 'fit'):\n            if self.split == 0:\n                df = pd.read_csv(os.path.join(self.labeled_data_dir, 'train.csv'))\n                ss = ShuffleSplit(n_splits=config.splits, test_size=config.val_size, random_state=config.seed)\n                for i, (train_idxs, valid_idxs) in enumerate(ss.split(df)):\n                    df.loc[valid_idxs, 'Split'] = i\n                df.to_csv('train_splits.csv', index=False)\n            else:\n                df = pd.read_csv('train_splits.csv')\n            self.labeled_train_dataset = PawpularityDataset(df[df['Split'] != self.split])\n            self.labeled_val_dataset = PawpularityDataset(df[df['Split'] == self.split])\n            \n        if stage in (None, 'test'):\n            test_df = pd.read_csv(os.path.join(self.labeled_data_dir, 'test.csv'))\n            self.test_dataset = PawpularityDataset(test_df, test=True)\n            \n    def train_dataloader(self):\n        labeled = DataLoader(\n            self.labeled_train_dataset,\n            batch_size=config.batch_size,\n            shuffle=True,\n            num_workers=2,\n            drop_last=True,\n        )\n        \n        unlabeled = DataLoader(\n            self.unlabeled_dataset,\n            batch_size=config.batch_size,\n            shuffle=True,\n            num_workers=2,\n            drop_last=True\n        )\n        \n        return {'labeled': labeled, 'unlabeled': unlabeled}\n    \n    def val_dataloader(self):\n        return DataLoader(\n            self.labeled_val_dataset,\n            batch_size=config.batch_size,\n            shuffle=False,\n            num_workers=2,\n            drop_last=False,\n        )\n    \n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=config.batch_size,\n            shuffle=False,\n            num_workers=2,\n            drop_last=False\n        )\n\n\nclass CanonicalSupervisedDataModule(LightningDataModule):\n    def __init__(self, data_dir, split):\n        super().__init__()\n        self.data_dir = data_dir\n        self.split = split\n    \n    def setup(self, stage=None):\n        if stage in (None, 'fit'):\n            if self.split == 0:\n                df = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n                ss = ShuffleSplit(n_splits=config.splits, test_size=config.val_size, random_state=config.seed)\n                for i, (train_idxs, valid_idxs) in enumerate(ss.split(df)):\n                    df.loc[valid_idxs, 'Split'] = i\n                df.to_csv('train_splits.csv', index=False)\n            else:\n                df = pd.read_csv('train_splits.csv')\n            self.train_dataset = PawpularityDataset(df[df['Split'] != self.split])\n            self.val_dataset = PawpularityDataset(df[df['Split'] == self.split])\n            \n        if stage in (None, 'test'):\n            test_df = pd.read_csv(os.path.join(self.data_dir, 'test.csv'))\n            self.test_dataset = PawpularityDataset(test_df, test=True)\n            \n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=config.batch_size,\n            shuffle=True,\n            num_workers=2,\n            drop_last=True,\n        )\n    \n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset,\n            batch_size=config.batch_size,\n            shuffle=False,\n            num_workers=2,\n            drop_last=False,\n        )\n    \n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=config.batch_size,\n            shuffle=False,\n            num_workers=2,\n            drop_last=False\n        )","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:51:37.358103Z","iopub.execute_input":"2021-10-16T18:51:37.358725Z","iopub.status.idle":"2021-10-16T18:51:37.392877Z","shell.execute_reply.started":"2021-10-16T18:51:37.358682Z","shell.execute_reply":"2021-10-16T18:51:37.391815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining PyTorch Lightning Systems\n\n### Supervised Learning","metadata":{}},{"cell_type":"code","source":"class SwinModel(pl.LightningModule):\n    def __init__(self, pretrained, split):\n        super().__init__()\n        \n        self.split = split\n        \n        self.backbone = timm.create_model(\n            config.model_name,\n            num_classes=0,\n            in_chans=3,\n        )\n        if pretrained:\n            self.backbone.load_state_dict(torch.load(\n                '../input/swin-tiny-patch4-window7-224-pretrained/swin_tiny_patch4_window7_224_pretrained.pth'\n            ))\n        \n        self.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(self.backbone.num_features, 1),\n        )\n        \n        self.criterion = nn.BCEWithLogitsLoss()\n    \n    def forward(self, x):\n        return self.fc(self.backbone(x))\n    \n    def training_step(self, batch, batch_idx):\n        images, labels = batch\n        images = my_transforms['train'](images)\n        labels = labels / 100.0\n        loss = self.criterion(self(images).squeeze(1), labels)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        with torch.no_grad():\n            images, labels = batch\n            images = my_transforms['val'](images)\n            labels = labels / 100.0\n            logits = self(images).squeeze(1)\n            loss = self.criterion(logits, labels)\n            self.log('val_loss', loss)\n    \n            mse_loss = torch.nn.MSELoss(reduction='sum')(logits, labels).detach()\n            return mse_loss, len(logits)\n    \n    def validation_epoch_end(self, outputs):\n        with torch.no_grad():\n            self.log('mse_loss', sum(o[0] for o in outputs) / sum(o[1] for o in outputs))\n    \n    def test_step(self, batch, batch_idx):\n        with torch.no_grad():\n            images = my_transforms['val'](batch)\n            logits = self(images)\n            predictions = 100.0 * torch.sigmoid(logits).detach().squeeze()\n            return predictions\n    \n    def test_epoch_end(self, outputs):\n        with torch.no_grad():\n            submission_df = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\n            submission_df['Pawpularity'] = torch.cat(outputs).detach().cpu()\n            submission_df.to_csv(f'submission_{self.split}.csv', index=False)\n    \n    def configure_optimizers(self):\n        return optim.AdamW(self.parameters(), lr=config.lr)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:51:37.395286Z","iopub.execute_input":"2021-10-16T18:51:37.395873Z","iopub.status.idle":"2021-10-16T18:51:37.414802Z","shell.execute_reply.started":"2021-10-16T18:51:37.395833Z","shell.execute_reply":"2021-10-16T18:51:37.413303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Meta Pseudo Labels\n\nSee https://arxiv.org/abs/2003.10580","metadata":{}},{"cell_type":"code","source":"class MetaPseudoLabelSystem(pl.LightningModule):\n    def __init__(self, teacher: nn.Module, student: nn.Module, split: int):\n        super().__init__()\n        self.automatic_optimization = False\n        \n        self.teacher = teacher        \n        self.student = student\n        self.split = split\n        \n        self.criterion = nn.BCEWithLogitsLoss()\n    \n    def forward(self, x):\n        return self.student(x)\n    \n    def training_step(self, batch, batch_idx):\n        unlabeled_images = batch['unlabeled']\n        labeled_images, labels = batch['labeled']\n        \n        unlabeled_images = my_transforms['train'](unlabeled_images)\n        labeled_images = my_transforms['train'](labeled_images)\n        labels = labels / 100.0\n        \n        student_opt, teacher_opt = self.optimizers()\n        \n        teacher_preds = torch.sigmoid(self.teacher(unlabeled_images).squeeze(1))\n        student_loss = self.criterion(self.student(unlabeled_images).squeeze(1), teacher_preds)\n        \n        student_opt.zero_grad()\n        self.manual_backward(student_loss)\n        student_opt.step()\n        \n        teacher_loss = self.criterion(self.student(labeled_images).squeeze(1), labels)\n        teacher_opt.zero_grad()\n        self.manual_backward(teacher_loss)\n        teacher_opt.step()\n        \n#         print(teacher_preds)\n        \n#         print(student_loss.detach().item())\n#         print(teacher_loss.detach().item())\n        \n        self.log('student_loss', student_loss)\n        self.log('teacher_loss', teacher_loss)\n    \n    def validation_step(self, batch, batch_idx):\n        with torch.no_grad():\n            images, labels = batch\n            images = my_transforms['val'](images)\n            labels = labels / 100.0\n\n            logits = self(images).squeeze(1)\n            loss = self.criterion(logits, labels)\n            self.log('val_loss', loss)\n\n            mse_loss = torch.nn.MSELoss(reduction='sum')(logits, labels).detach()\n            return mse_loss, len(logits)\n    \n    def validation_epoch_end(self, outputs):\n        with torch.no_grad():\n            self.log('mse_loss', sum(o[0] for o in outputs) / sum(o[1] for o in outputs))\n    \n    def configure_optimizers(self):\n        return optim.AdamW(self.student.parameters(), config.lr), optim.AdamW(self.teacher.parameters(), config.lr)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:51:37.417202Z","iopub.execute_input":"2021-10-16T18:51:37.417839Z","iopub.status.idle":"2021-10-16T18:51:37.436693Z","shell.execute_reply.started":"2021-10-16T18:51:37.417731Z","shell.execute_reply":"2021-10-16T18:51:37.435607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training + CV\n\nNote that attempting memory management with `del` and `gc.collect()` is probably bad practice.","metadata":{}},{"cell_type":"code","source":"pawpularity_root = '../input/petfinder-pawpularity-score/'\nunlabeled_globs = [\n    '../input/cat-dataset/CAT_0?/*.jpg',\n    '../input/stanford-dogs-dataset/images/Images/*/*.jpg',\n]\n\nlogger = CSVLogger('logs')\nfor split in range(config.splits):\n    my_teacher = SwinModel(pretrained=True, split=split)\n    teacher_pretrainer = pl.Trainer(max_epochs=config.epochs.pretrain, callbacks=[EarlyStopping(monitor='val_loss'), GPUStatsMonitor()], logger=logger, **config.trainer)\n    pretrain_datamodule = CanonicalSupervisedDataModule(pawpularity_root, split)\n    teacher_pretrainer.fit(my_teacher, datamodule=pretrain_datamodule)\n    \n    del teacher_pretrainer\n    del pretrain_datamodule\n    gc.collect()\n    \n    my_student = SwinModel(pretrained=True, split=split)\n    mpsl = MetaPseudoLabelSystem(my_teacher, my_student, split)\n    mpsl_datamodule = PawpularitySSLDataModule(pawpularity_root, split, unlabeled_globs)\n    mpsl_trainer = pl.Trainer(max_epochs=config.epochs.meta_ps, callbacks=[EarlyStopping(monitor='val_loss'), GPUStatsMonitor()], logger=logger, **config.trainer)\n    mpsl_trainer.fit(mpsl, datamodule=mpsl_datamodule)\n    \n    del mpsl_trainer\n    del mpsl_datamodule\n    del mpsl\n    del my_teacher\n    gc.collect()\n    \n    for param in my_student.backbone.parameters():\n        param.requires_grad = False\n    finetuner = pl.Trainer(max_epochs=config.epochs.finetune, callbacks=[EarlyStopping(monitor='val_loss'), GPUStatsMonitor()], logger=logger, **config.trainer)\n    finetune_datamodule = CanonicalSupervisedDataModule(pawpularity_root, split)\n    finetuner.fit(my_student, datamodule=finetune_datamodule)\n    \n    finetuner.test(my_student, datamodule=finetune_datamodule)\n\n    del finetuner\n    del finetune_datamodule\n    del my_student\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:51:37.438717Z","iopub.execute_input":"2021-10-16T18:51:37.439142Z","iopub.status.idle":"2021-10-16T18:55:13.695025Z","shell.execute_reply.started":"2021-10-16T18:51:37.439089Z","shell.execute_reply":"2021-10-16T18:55:13.693761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submit Predictions","metadata":{}},{"cell_type":"code","source":"test_predictions = []\nfor split in range(config.splits):\n    df = pd.read_csv(f'submission_{split}.csv')\n    test_predictions.append(df['Pawpularity'])\nconcat = pd.concat(test_predictions, 1)\n\nsubmission_df = pd.read_csv('../input/petfinder-pawpularity-score/sample_submission.csv')\nsubmission_df['Pawpularity'] = concat.mean(1)\nsubmission_df.to_csv('submission.csv', index=False)\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2021-10-16T18:55:13.697688Z","iopub.execute_input":"2021-10-16T18:55:13.698506Z","iopub.status.idle":"2021-10-16T18:55:13.751305Z","shell.execute_reply.started":"2021-10-16T18:55:13.698464Z","shell.execute_reply":"2021-10-16T18:55:13.750475Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
